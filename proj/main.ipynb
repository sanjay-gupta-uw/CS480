{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ImmyKcwQPvJB",
    "outputId": "afe0e42e-4f47-4c68-dcef-f6e98146c1b8"
   },
   "source": [
    "### Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "\n",
    "1. In Colab, open tab Runtime > Change runtime type, choose *python3* and *T4 GPU*.\n",
    "2. Run the following command to set up the environment. (Takes ~ 1.5 min)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.16.1 (from tensorflow[and-cuda]==2.16.1)\n",
      "  Using cached tensorflow-2.16.1-cp311-cp311-win_amd64.whl.metadata (3.5 kB)\n",
      "Collecting tensorflow-intel==2.16.1 (from tensorflow==2.16.1->tensorflow[and-cuda]==2.16.1)\n",
      "  Using cached tensorflow_intel-2.16.1-cp311-cp311-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting nvidia-cublas-cu12==12.3.4.1 (from tensorflow[and-cuda]==2.16.1)\n",
      "  Using cached nvidia_cublas_cu12-12.3.4.1-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.3.101 (from tensorflow[and-cuda]==2.16.1)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.3.101-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cuda-nvcc-cu12==12.3.107 (from tensorflow[and-cuda]==2.16.1)\n",
      "  Using cached nvidia_cuda_nvcc_cu12-12.3.107-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.3.107 (from tensorflow[and-cuda]==2.16.1)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.3.107-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.3.101 (from tensorflow[and-cuda]==2.16.1)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.3.101-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.7.29 (from tensorflow[and-cuda]==2.16.1)\n",
      "  Using cached nvidia_cudnn_cu12-8.9.7.29-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.12.1 (from tensorflow[and-cuda]==2.16.1)\n",
      "  Using cached nvidia_cufft_cu12-11.0.12.1-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.4.107 (from tensorflow[and-cuda]==2.16.1)\n",
      "  Using cached nvidia_curand_cu12-10.3.4.107-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.5.4.101 (from tensorflow[and-cuda]==2.16.1)\n",
      "  Using cached nvidia_cusolver_cu12-11.5.4.101-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.2.0.103 (from tensorflow[and-cuda]==2.16.1)\n",
      "  Using cached nvidia_cusparse_cu12-12.2.0.103-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "INFO: pip is looking at multiple versions of tensorflow[and-cuda] to determine which version is compatible with other requirements. This could take a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement nvidia-nccl-cu12==2.19.3; extra == \"and-cuda\" (from tensorflow[and-cuda]) (from versions: 0.0.1.dev5)\n",
      "ERROR: No matching distribution found for nvidia-nccl-cu12==2.19.3; extra == \"and-cuda\"\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow[and-cuda]==2.16.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with importing our standard set of libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "CUDA available: False\n",
      "Tensorflow version:  2.17.0\n"
     ]
    }
   ],
   "source": [
    "# set up GPU \n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"CUDA available:\", tf.test.is_built_with_cuda())\n",
    "# tensorflow version\n",
    "print(\"Tensorflow version: \", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "# Normalize the CSV file\n",
    "def normalize(df):\n",
    "    # Convert all columns except ID (first) to float64 to prevent dtype issues\n",
    "    df.iloc[:, 0] = df.iloc[:, 0].astype('int64')\n",
    "    df.iloc[:, -6:] = df.iloc[:, -6:].astype('float64')\n",
    "\n",
    "    # Apply log-10 transformation\n",
    "    df.iloc[:, -6:] = np.log10(df.iloc[:, -6:] + 1e-4)\n",
    "\n",
    "    # Remove outliers (more than 3 standard deviations from the mean)\n",
    "    df = df[\n",
    "        (np.abs(df.iloc[:, -6:] - df.iloc[:, -6:].mean()) <= \n",
    "            (3 * df.iloc[:, -6:].std())).all(axis=1)\n",
    "    ]\n",
    "\n",
    "    # Normalize the traits\n",
    "    min_train = df.iloc[:, -6:].min()\n",
    "    max_train = df.iloc[:, -6:].max()\n",
    "    df.iloc[:, -6:] = (df.iloc[:, -6:] - min_train) / (max_train - min_train)\n",
    "\n",
    "\n",
    "    duplicate_ids = df[df.duplicated(subset=[df.columns[0]], keep=False)]\n",
    "    if not duplicate_ids.empty:\n",
    "        print(f\"Duplicate IDs found: {duplicate_ids[df.columns[0]]}\")\n",
    "    else :\n",
    "        print(\"No duplicate IDs found\")\n",
    "\n",
    "    return df, min_train, max_train\n",
    "\n",
    "\n",
    "# ImageDataset Class\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        self.image_dir = img_dir\n",
    "        self.img_labels = [f for f in os.listdir(img_dir) if os.path.isfile(os.path.join(img_dir, f))]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_name = os.path.join(self.image_dir, self.img_labels[idx])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        # ID Needs .jpeg removed        \n",
    "        id = self.img_labels[idx].split('.')[0]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, id\n",
    "\n",
    "# Baseline Dataset Class (Inherits from ImageDataset, adds trait labels)\n",
    "class BaselineDataset(ImageDataset):\n",
    "    def __init__(self, dataframe, img_dir, transform=None, is_train=True):\n",
    "        super(BaselineDataset, self).__init__(img_dir, transform)\n",
    "        self.is_train = is_train\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load structure: [id] [world climate1] ... [world climate6] [feature1] [feature2] ... [featureN] [trait1] [trait2] ... [trait6]\n",
    "        id = self.dataframe.iloc[idx, 0].astype(int)\n",
    "        img_name = os.path.join(self.image_dir, str(id) + '.jpeg')\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        if self.is_train:\n",
    "            features = self.dataframe.iloc[idx, 1:-6].values.astype('float32')\n",
    "            # Load plant trait labels (6 columns)\n",
    "            traits = self.dataframe.iloc[idx, -6:].values.astype('float32')\n",
    "            \n",
    "            return image, id, features, traits\n",
    "\n",
    "        features = self.dataframe.iloc[idx, 1:].values.astype('float32')\n",
    "        return image, id, features\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataloaders for Each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dataloaders for CNNs (Images) ###\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "k_folds = 5\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "# Define transformations for image data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)), # Upscale images to 512x512\n",
    "    transforms.RandomHorizontalFlip(),  \n",
    "    transforms.RandomVerticalFlip(),  \n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),  # Adjust to [0.9, 1.1]\n",
    "    transforms.ToTensor() \n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),  # Resize images to 512x512\n",
    "    transforms.ToTensor()           # Convert images to PyTorch tensors\n",
    "])\n",
    "\n",
    "# CSV files\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "print(f\"Number of training samples before normalization: {len(train_df)}\")\n",
    "train_df, min_train, max_train = normalize(train_df)\n",
    "print(f\"Number of training samples after normalization: {len(train_df)}\")\n",
    "\n",
    "# Load train dataset\n",
    "train_dataset = BaselineDataset(dataframe=train_df, img_dir='data/images/train_images/', transform=test_transform)\n",
    "# print columns in train_dataset df\n",
    "print(\"Base line Cols: \", train_dataset.dataframe.columns)\n",
    "\n",
    "# Load test dataset\n",
    "test_dataset = BaselineDataset(dataframe=test_df, img_dir='data/images/test_images/', transform=transform, is_train=False)\n",
    "\n",
    "batch_size = 16\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import inception_v3, Inception_V3_Weights\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from xgboost import XGBRegressor\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Define the number of traits and features\n",
    "NUM_TRAITS = 6\n",
    "\n",
    "class FeatureExtractorCNN(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super(FeatureExtractorCNN, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        in_features = base_model.fc.in_features\n",
    "        self.base_model.fc = nn.Identity()  # Remove the final classification layer to extract features\n",
    "\n",
    "        # Adding a dropout layer to the extracted image features before outputting\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, images):\n",
    "        # Process images through InceptionV3\n",
    "        image_features = self.base_model(images)\n",
    "        \n",
    "        if isinstance(image_features, tuple):\n",
    "            image_features = image_features[0]\n",
    "        \n",
    "        # Apply dropout to the extracted features\n",
    "        image_features = self.dropout(image_features)\n",
    "        \n",
    "        return image_features\n",
    "\n",
    "# Load the InceptionV3 model\n",
    "base_model = inception_v3(weights=Inception_V3_Weights.DEFAULT)\n",
    "\n",
    "# Unfreeze the last block of layers for fine-tuning\n",
    "for param in base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in base_model.Mixed_7c.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "feature_extractor = FeatureExtractorCNN(base_model).to(device)\n",
    "\n",
    "# Initialize optimizer and learning rate scheduler\n",
    "optimizer = torch.optim.RMSprop(filter(lambda p: p.requires_grad, feature_extractor.parameters()), lr=1e-4, weight_decay=0.0001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "critertion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training pipeline (6 points)\n",
    "\n",
    "\n",
    "Finally, we perform training on the two networks. The training consists of two steps: (1) Updating discriminators for n_critic steps (such that we have an optimal critic): here we use an aggregation of three loss functions, (a) The real loss (the output scalar of the critic for real images); (b) The fake loss (same value for fake images); (c) The [gradient penalty](https://arxiv.org/pdf/1704.00028). (2) Updating generators by only considering the fake loss (to fool the critic).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "AKkYiOC2P9mi",
    "outputId": "238aca44-9928-40df-f20f-45615efe7853"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(feature_extractor, training_dataset, num_epochs=10):\n",
    "    fold_results = []\n",
    "    best_val_rmse = float(\"inf\")  \n",
    "\n",
    "    # Training Loop\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(train_dataset)):\n",
    "        print(f'Fold {fold+1}/{k_folds}')\n",
    "\n",
    "        # Subset datasets for current fold\n",
    "        train_subsampler = Subset(train_dataset, train_idx)\n",
    "        val_subsampler = Subset(train_dataset, val_idx)\n",
    "\n",
    "        # Data loaders\n",
    "        train_loader = DataLoader(train_subsampler, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_subsampler, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Initialize XGBoost model\n",
    "        xgb_model = XGBRegressor(objective=\"reg:squarederror\", n_estimators=100, learning_rate=0.1)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "\n",
    "            # Training Phase\n",
    "            feature_extractor.train()  # Set the feature extractor to training mode\n",
    "            train_features = []\n",
    "            train_traits = []\n",
    "\n",
    "            total_batches = len(train_loader)\n",
    "            with tqdm(total=total_batches, desc=f'Fold {fold+1}, Epoch {epoch+1}/{num_epochs}', unit='batch') as pbar:\n",
    "                for batch, (images, _, additional_features, traits) in enumerate(train_loader):\n",
    "                    images, additional_features = images.to(device), additional_features.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # Extract features using InceptionV3\n",
    "                    image_features = feature_extractor(images)  \n",
    "                    \n",
    "                    # Combine with additional features\n",
    "                    combined_features = np.hstack((image_features.cpu().detach().numpy(), additional_features.cpu().detach().numpy()))\n",
    "                    train_features.append(combined_features)\n",
    "                    train_traits.append(traits.cpu().detach().numpy())\n",
    "\n",
    "                    pbar.update(1)\n",
    "\n",
    "            # Stack features and traits for XGBoost\n",
    "            train_features = np.vstack(train_features)\n",
    "            train_traits = np.vstack(train_traits)\n",
    "\n",
    "            # Train XGBoost model\n",
    "            xgb_model.fit(train_features, train_traits)\n",
    "\n",
    "             # Calculate loss\n",
    "            predictions = xgb_model.predict(train_features)\n",
    "            loss = criterion(torch.tensor(predictions).to(device), torch.tensor(train_traits).to(device))\n",
    "\n",
    "            # Backpropagate and update the feature extractor\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Validation Phase\n",
    "            feature_extractor.eval()  # Set the feature extractor to evaluation mode\n",
    "            val_features = []\n",
    "            val_traits = []\n",
    "\n",
    "            with torch.no_grad():  # Only use torch.no_grad() during validation\n",
    "                for images, _, additional_features, traits in val_loader:\n",
    "                    images, additional_features = images.to(device), additional_features.to(device)\n",
    "                    \n",
    "                    image_features = feature_extractor(images)\n",
    "                    combined_features = np.hstack((image_features.cpu().numpy(), additional_features.cpu().numpy()))\n",
    "                    val_features.append(combined_features)\n",
    "                    val_traits.append(traits.cpu().numpy())\n",
    "\n",
    "            val_features = np.vstack(val_features)\n",
    "            val_traits = np.vstack(val_traits)\n",
    "\n",
    "            # Validate XGBoost model\n",
    "            val_predictions = xgb_model.predict(val_features)\n",
    "            val_rmse = np.sqrt(mean_squared_error(val_traits, val_predictions))\n",
    "            print(f'Fold {fold+1}, Epoch {epoch+1}/{num_epochs}, Validation RMSE: {val_rmse:.4f}')\n",
    "\n",
    "            scheduler.step(val_rmse)\n",
    "\n",
    "\n",
    "            # Save the best performing models\n",
    "            if val_rmse < best_val_rmse:\n",
    "                best_val_rmse = val_rmse\n",
    "                print(f'New best model found at Fold {fold+1}, Epoch {epoch+1}, Saving the model...')\n",
    "                torch.save(feature_extractor.state_dict(), f'best_feature_extractor_fold_{fold+1}.pth')\n",
    "                xgb_model.save_model(f'best_xgb_model_fold_{fold+1}.json')   \n",
    "        \n",
    "        fold_results.append(best_val_rmse)\n",
    "        \n",
    "    print(f'Cross-Validation Results: {fold_results}')\n",
    "    print(f'Mean RMSE across folds: {np.mean(fold_results):.4f}, Std Dev: {np.std(fold_results):.4f}')\n",
    "\n",
    "\n",
    "# Train the model\n",
    "train_model(feature_extractor, train_dataset, num_epochs=10)\n",
    "\n",
    "# Save the models\n",
    "torch.save(feature_extractor.state_dict(), 'feature_extractor.pth')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(feature_extractor, regression, test_loader, train_min, train_max):\n",
    "    feature_extractor.eval()\n",
    "    test_features = []\n",
    "    test_ids = []\n",
    "    total_batches = len(test_loader)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch, data in enumerate(test_loader):\n",
    "            # Unpack data\n",
    "            images, ids, additional_features = data\n",
    "            images, additional_features = images.to(device), additional_features.to(device)\n",
    "            \n",
    "            # Extract features from images\n",
    "            image_features = feature_extractor(images)\n",
    "            combined_features = torch.cat((image_features, additional_features), dim=1).cpu().numpy()\n",
    "            test_features.append(combined_features)\n",
    "            test_ids.extend(ids.numpy().astype(int))  # Store the IDs as integers\n",
    "    \n",
    "            print(f\"Testing Progress: [{batch + 1}/{total_batches}] Complete\", end='\\r')\n",
    "    \n",
    "    test_features = np.vstack(test_features)\n",
    "    test_predictions = regression.predict(test_features)\n",
    "    \n",
    "    # Renormalize the predictions\n",
    "    train_min = train_min.values\n",
    "    train_max = train_max.values\n",
    "    test_predictions = test_predictions * (train_max - train_min) + train_min\n",
    "    \n",
    "    # Undo the log10 transformation\n",
    "    test_predictions = 10**test_predictions\n",
    "    \n",
    "    # Combine the IDs with the predictions\n",
    "    results = np.column_stack((test_ids, test_predictions))\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Load the model\n",
    "feature_extractor.load_state_dict(torch.load('feature_extractor.pth'))\n",
    "xgb_model.load_model('xgb_model.json')\n",
    "\n",
    "# Test the model\n",
    "test_predictions = test_model(feature_extractor, xgb_model, test_loader, min_train, max_train)\n",
    "\n",
    "# Define the header as specified\n",
    "header = \"id,X4,X11,X18,X26,X50,X3112\"\n",
    "\n",
    "# Save the model and predictions with the specified header and ensure IDs are integers\n",
    "np.savetxt('submission.csv', test_predictions, delimiter=',', header=header, comments='', fmt='%d,' + ','.join(['%.6f'] * 6))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "wgan.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
