{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ImmyKcwQPvJB",
    "outputId": "afe0e42e-4f47-4c68-dcef-f6e98146c1b8"
   },
   "source": [
    "### Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "\n",
    "1. In Colab, open tab Runtime > Change runtime type, choose *python3* and *T4 GPU*.\n",
    "2. Run the following command to set up the environment. (Takes ~ 1.5 min)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: validators in c:\\users\\sanja\\cs480\\cs480\\proj\\pyvenv\\lib\\site-packages (0.33.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\sanja\\cs480\\cs480\\proj\\pyvenv\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\sanja\\cs480\\cs480\\proj\\pyvenv\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sanja\\cs480\\cs480\\proj\\pyvenv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sanja\\cs480\\cs480\\proj\\pyvenv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sanja\\cs480\\cs480\\proj\\pyvenv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sanja\\cs480\\cs480\\proj\\pyvenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install --quiet ipython[notebook]==7.34.0 \"setuptools>=68.0.0,<68.3.0\" torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu121\n",
    "! pip install --quiet --upgrade matplotlib\n",
    "! pip install --quiet --upgrade ipython\n",
    "! pip install --quiet numpy==1.26.4\n",
    "! pip install validators pandas \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with importing our standard set of libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sm_50', 'sm_60', 'sm_61', 'sm_70', 'sm_75', 'sm_80', 'sm_86', 'sm_90']\n",
      "Everything looks good; continue\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim, autograd\n",
    "import torchvision.models as models\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "\n",
    "%matplotlib inline\n",
    "torch.set_num_threads(1)\n",
    "torch.manual_seed(1)\n",
    "\n",
    "print(torch.cuda.get_arch_list())\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "if device == torch.device(\"cuda:0\"):\n",
    "  print('Everything looks good; continue')\n",
    "else:\n",
    "  # It is OK if you cannot connect to a GPU. In this case, training the model for\n",
    "  # 2 epoch is sufficient to get full mark. (NOTE THAT 2 epoch takes approximately 1.5 hours to train for CPU)\n",
    "  print('GPU is not detected. Make sure you have chosen the right runtime type')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "# Normalize the CSV file\n",
    "def normalize(df):\n",
    "    # Convert all columns except ID (first) to float64 to prevent dtype issues\n",
    "    df.iloc[:, 0] = df.iloc[:, 0].astype('int64')\n",
    "    df.iloc[:, -6:] = df.iloc[:, -6:].astype('float64')\n",
    "\n",
    "    # Apply log-10 transformation\n",
    "    df.iloc[:, -6:] = np.log10(df.iloc[:, -6:] + 1e-4)\n",
    "\n",
    "    # Remove outliers (more than 3 standard deviations from the mean)\n",
    "    df = df[\n",
    "        (np.abs(df.iloc[:, -6:] - df.iloc[:, -6:].mean()) <= \n",
    "            (3 * df.iloc[:, -6:].std())).all(axis=1)\n",
    "    ]\n",
    "\n",
    "    # Normalize the traits\n",
    "    min_train = df.iloc[:, -6:].min()\n",
    "    max_train = df.iloc[:, -6:].max()\n",
    "    df.iloc[:, -6:] = (df.iloc[:, -6:] - min_train) / (max_train - min_train)\n",
    "\n",
    "\n",
    "    duplicate_ids = df[df.duplicated(subset=[df.columns[0]], keep=False)]\n",
    "    if not duplicate_ids.empty:\n",
    "        print(f\"Duplicate IDs found: {duplicate_ids[df.columns[0]]}\")\n",
    "    else :\n",
    "        print(\"No duplicate IDs found\")\n",
    "\n",
    "    return df, min_train, max_train\n",
    "\n",
    "\n",
    "# ImageDataset Class\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        self.image_dir = img_dir\n",
    "        self.img_labels = [f for f in os.listdir(img_dir) if os.path.isfile(os.path.join(img_dir, f))]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_name = os.path.join(self.image_dir, self.img_labels[idx])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        # ID Needs .jpeg removed        \n",
    "        id = self.img_labels[idx].split('.')[0]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, id\n",
    "\n",
    "# Baseline Dataset Class (Inherits from ImageDataset, adds trait labels)\n",
    "class BaselineDataset(ImageDataset):\n",
    "    def __init__(self, dataframe, img_dir, transform=None, is_train=True):\n",
    "        super(BaselineDataset, self).__init__(img_dir, transform)\n",
    "        self.is_train = is_train\n",
    "\n",
    "        # Select the ID (first column) and the last 6 columns (traits)\n",
    "        self.dataframe = dataframe.iloc[:, [0] + list(range(-6, 0))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load structure: [id] [trait1] [trait2] ... [trait6]\n",
    "        id = self.dataframe.iloc[idx, 0].astype(int)\n",
    "        img_name = os.path.join(self.image_dir, str(id) + '.jpeg')\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        if self.is_train:\n",
    "            # Load plant trait labels (6 columns)\n",
    "            traits = self.dataframe.iloc[idx, 1:].values.astype('float32')\n",
    "            \n",
    "            return image, id, traits\n",
    "\n",
    "        return image, id\n",
    "    \n",
    "\n",
    "# Plasticity Dataset Class (Inherits from ImageDataset, adds all but the six climate labels)\n",
    "class PlasticityDataset(BaselineDataset):\n",
    "    def __init__(self, dataframe, img_dir, transform=None, is_train=True):\n",
    "        super(PlasticityDataset, self).__init__(dataframe, img_dir, transform, is_train)\n",
    "        # After call to super, self.dataframe is the dataframe with the first column (id) and the last 6 columns (traits) and has been properly normalized\n",
    "        # We want to add the features to the dataframe (excluding those pertaining to world climate, and join them by id column, and have them appear before the trait columns)\n",
    "        non_climate_features = dataframe.iloc[:, [0] + list(range(7, dataframe.shape[1] - 6))]\n",
    "        # Merging on the 'id' column (make sure 'id' is set correctly in both)\n",
    "        original_df = self.dataframe\n",
    "        self.dataframe = pd.merge(self.dataframe, non_climate_features, on=\"id\")\n",
    "        # Reorder columns so that the features appear before the traits\n",
    "        ordered_columns = [original_df.columns[0]] + list(non_climate_features.columns[1:]) + list(original_df.columns[1:])\n",
    "        self.dataframe = self.dataframe[ordered_columns]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load structure: [id] [world climate1] ... [world climate6] [feature1] [feature2] ... [featureN] [trait1] [trait2] ... [trait6]\n",
    "        id = self.dataframe.iloc[idx, 0].astype(int)\n",
    "        img_name = os.path.join(self.image_dir, str(id) + '.jpeg')\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        if self.is_train:\n",
    "            features = self.dataframe.iloc[idx, 1:-6].values.astype('float32')\n",
    "            # Load plant trait labels (6 columns)\n",
    "            traits = self.dataframe.iloc[idx, -6:].values.astype('float32')\n",
    "            \n",
    "            return image, id, features, traits\n",
    "\n",
    "        features = self.dataframe.iloc[idx, 1:].values.astype('float32')\n",
    "        return image, id, features\n",
    "\n",
    "# World Climate Dataset Class (Inherits from PlasticityDataset, adds the six climate labels)\n",
    "class WorldClimateDataset(PlasticityDataset):\n",
    "    def __init__(self, dataframe, img_dir, transform=None, is_train=True):\n",
    "        super(WorldClimateDataset, self).__init__(dataframe, img_dir, transform, is_train)\n",
    "        # After call to super, self.dataframe is the dataframe with the first column (id) Plasticity columns and traits and has been properly normalized\n",
    "        # We want to add the features to the dataframe (world climate, and join them by id column, and have them appear right after id column)\n",
    "        climate_features = dataframe.iloc[:, 0:7]\n",
    "        # Merging on the 'id' column (make sure 'id' is set correctly in both)\n",
    "        original_df = self.dataframe\n",
    "        self.dataframe = pd.merge(self.dataframe, climate_features, on=self.dataframe.columns[0])\n",
    "        # Reorder columns so that the features appear before the traits\n",
    "        ordered_columns = [original_df.columns[0]] + list(climate_features.columns[1:]) + list(original_df.columns[1:])\n",
    "        self.dataframe = self.dataframe[ordered_columns]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load structure: [id] [world climate1] ... [world climate6] [feature1] [feature2] ... [featureN] [trait1] [trait2] ... [trait6]\n",
    "        id = self.dataframe.iloc[idx, 0].astype(int)\n",
    "        img_name = os.path.join(self.image_dir, str(id) + '.jpeg')\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        if self.is_train:\n",
    "            features = self.dataframe.iloc[idx, 1:-6].values.astype('float32')\n",
    "            # Load plant trait labels (6 columns)\n",
    "            traits = self.dataframe.iloc[idx, -6:].values.astype('float32')\n",
    "            \n",
    "            return image, id, features, traits\n",
    "\n",
    "        features = self.dataframe.iloc[idx, 1:].values.astype('float32')\n",
    "        return image, id, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataloaders for Each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples before normalization: 43363\n",
      "No duplicate IDs found\n",
      "Number of training samples after normalization: 39556\n",
      "Base line Cols:  Index(['id', 'X4_mean', 'X11_mean', 'X18_mean', 'X26_mean', 'X50_mean',\n",
      "       'X3112_mean'],\n",
      "      dtype='object')\n",
      "Plasticity Cols:  Index(['id', 'SOIL_bdod_0.5cm_mean_0.01_deg',\n",
      "       'SOIL_bdod_100.200cm_mean_0.01_deg', 'SOIL_bdod_15.30cm_mean_0.01_deg',\n",
      "       'SOIL_bdod_30.60cm_mean_0.01_deg', 'SOIL_bdod_5.15cm_mean_0.01_deg',\n",
      "       'SOIL_bdod_60.100cm_mean_0.01_deg', 'SOIL_cec_0.5cm_mean_0.01_deg',\n",
      "       'SOIL_cec_100.200cm_mean_0.01_deg', 'SOIL_cec_15.30cm_mean_0.01_deg',\n",
      "       ...\n",
      "       'VOD_X_1997_2018_multiyear_mean_m09',\n",
      "       'VOD_X_1997_2018_multiyear_mean_m10',\n",
      "       'VOD_X_1997_2018_multiyear_mean_m11',\n",
      "       'VOD_X_1997_2018_multiyear_mean_m12', 'X4_mean', 'X11_mean', 'X18_mean',\n",
      "       'X26_mean', 'X50_mean', 'X3112_mean'],\n",
      "      dtype='object', length=164)\n",
      "World Climate Cols:  Index(['id', 'WORLDCLIM_BIO1_annual_mean_temperature',\n",
      "       'WORLDCLIM_BIO12_annual_precipitation',\n",
      "       'WORLDCLIM_BIO13.BIO14_delta_precipitation_of_wettest_and_dryest_month',\n",
      "       'WORLDCLIM_BIO15_precipitation_seasonality',\n",
      "       'WORLDCLIM_BIO4_temperature_seasonality',\n",
      "       'WORLDCLIM_BIO7_temperature_annual_range',\n",
      "       'SOIL_bdod_0.5cm_mean_0.01_deg', 'SOIL_bdod_100.200cm_mean_0.01_deg',\n",
      "       'SOIL_bdod_15.30cm_mean_0.01_deg',\n",
      "       ...\n",
      "       'VOD_X_1997_2018_multiyear_mean_m09',\n",
      "       'VOD_X_1997_2018_multiyear_mean_m10',\n",
      "       'VOD_X_1997_2018_multiyear_mean_m11',\n",
      "       'VOD_X_1997_2018_multiyear_mean_m12', 'X4_mean', 'X11_mean', 'X18_mean',\n",
      "       'X26_mean', 'X50_mean', 'X3112_mean'],\n",
      "      dtype='object', length=170)\n"
     ]
    }
   ],
   "source": [
    "### Dataloaders for CNNs (Images) ###\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define transformations for image data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)), # Upscale images to 512x512\n",
    "    transforms.RandomHorizontalFlip(),  \n",
    "    transforms.RandomVerticalFlip(),  \n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),  # Adjust to [0.9, 1.1]\n",
    "    transforms.ToTensor() \n",
    "])\n",
    "\n",
    "# CSV files\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "print(f\"Number of training samples before normalization: {len(train_df)}\")\n",
    "train_df, min_train, max_train = normalize(train_df)\n",
    "\n",
    "\n",
    "print(f\"Number of training samples after normalization: {len(train_df)}\")\n",
    "\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "batch_size = 16\n",
    "############################################################################\n",
    "# Load train dataset\n",
    "train_dataset = BaselineDataset(dataframe=train_df, img_dir='data/images/train_images/', transform=transform)\n",
    "# print columns in train_dataset df\n",
    "print(\"Base line Cols: \", train_dataset.dataframe.columns)\n",
    "\n",
    "# split train_dataset into train and val\n",
    "num_train_images = len(train_dataset) \n",
    "train_size = int(0.8 * num_train_images)\n",
    "val_size = num_train_images - train_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# # Load test dataset\n",
    "test_dataset = BaselineDataset(dataframe=test_df, img_dir='data/images/test_images/', transform=transform, is_train=False)\n",
    "\n",
    "baseline_train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "baseline_val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "baseline_test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "############################################################################\n",
    "# Load train dataset for plasticity\n",
    "train_dataset = PlasticityDataset(dataframe=train_df, img_dir='data/images/train_images/', transform=transform)\n",
    "print(\"Plasticity Cols: \", train_dataset.dataframe.columns)\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "test_dataset = PlasticityDataset(dataframe=test_df, img_dir='data/images/test_images/', transform=transform, is_train=False)\n",
    "\n",
    "plasticity_train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "plasticity_val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "plasticity_test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "############################################################################\n",
    "# Load train dataset for world climate\n",
    "train_dataset = WorldClimateDataset(dataframe=train_df, img_dir='data/images/train_images/', transform=transform)\n",
    "print(\"World Climate Cols: \", train_dataset.dataframe.columns)\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "test_dataset = WorldClimateDataset(dataframe=test_df, img_dir='data/images/test_images/', transform=transform, is_train=False)\n",
    "\n",
    "world_climate_train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "world_climate_val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "world_climate_test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import inception_v3, Inception_V3_Weights\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "# Define the number of traits and features\n",
    "NUM_TRAITS = 6\n",
    "NUM_FEATURES = 157 \n",
    "\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, base_model, num_features, num_traits):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        in_features = self.base_model.fc.in_features # need to do this here before changing the fc layer    \n",
    "        self.base_model.fc = nn.Identity()  # Remove the final classification layer\n",
    "        \n",
    "        # Add a fully connected layer for the additional features\n",
    "        self.feature_fc = nn.Linear(num_features, 128)\n",
    "\n",
    "        # Combine the image features and additional features\n",
    "        self.combined_fc = nn.Linear(in_features + 128, num_traits)\n",
    "\n",
    "    def forward(self, images, features):\n",
    "        # Process images through InceptionV3\n",
    "        image_features = self.base_model(images)\n",
    "\n",
    "        # Handle InceptionV3 outputs (extract main logits)\n",
    "        if isinstance(image_features, tuple):\n",
    "            image_features = image_features.logits\n",
    "\n",
    "        # Process additional features through a fully connected layer\n",
    "        feature_output = self.feature_fc(features)\n",
    "\n",
    "        # Concatenate the image features and the additional features\n",
    "        combined_input = torch.cat((image_features, feature_output), dim=1)\n",
    "\n",
    "        # Pass the combined input through the final layer to predict traits\n",
    "        output = self.combined_fc(combined_input)\n",
    "        return output\n",
    "\n",
    "# Load the InceptionV3 model\n",
    "base_model = inception_v3(weights=Inception_V3_Weights.DEFAULT)\n",
    "\n",
    "# Initialize the Plasticity Model\n",
    "plasticity_model = CombinedModel(base_model, num_features=NUM_FEATURES, num_traits=NUM_TRAITS)\n",
    "\n",
    "# Initialize the World Climate Model\n",
    "# world_climate_model = CombinedModel(base_model, num_features=NUM_FEATURES + 6, num_traits=NUM_TRAITS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before Training \n",
    "\n",
    "Next we define the two models and the optimizers. We use the [AdamW](https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html) algorithm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(base_model.parameters(), lr=0.001, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training pipeline (6 points)\n",
    "\n",
    "\n",
    "Finally, we perform training on the two networks. The training consists of two steps: (1) Updating discriminators for n_critic steps (such that we have an optimal critic): here we use an aggregation of three loss functions, (a) The real loss (the output scalar of the critic for real images); (b) The fake loss (same value for fake images); (c) The [gradient penalty](https://arxiv.org/pdf/1704.00028). (2) Updating generators by only considering the fake loss (to fool the critic).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "AKkYiOC2P9mi",
    "outputId": "238aca44-9928-40df-f20f-45615efe7853"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1] Progress: [5.71%]\r"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10, has_features=False):\n",
    "    model = model.to(device)  # Ensure the model is on the GPU if available\n",
    "    losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training Loop\n",
    "        model.train()  # Set the model to training mode\n",
    "        running_loss = 0.0\n",
    "        total_batches = len(train_loader) * num_epochs\n",
    "        for batch, data in enumerate(train_loader):\n",
    "            # Calculate progress and print it\n",
    "            progress = 100 * (epoch * len(train_loader) + batch + 1) / total_batches\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}] Progress: [{progress:.2f}%]', end='\\r')\n",
    "\n",
    "            # Unpack data according to whether features are included\n",
    "            if has_features:\n",
    "                images, ids, features, traits = data\n",
    "                images, ids, features, traits = images.to(device), ids.to(device), features.to(device), traits.to(device)\n",
    "                outputs = model(images, features)\n",
    "            else:\n",
    "                images, ids, traits = data\n",
    "                images, ids, traits = images.to(device), ids.to(device), traits.to(device)\n",
    "                outputs = model(images)\n",
    "\n",
    "            if isinstance(outputs, tuple):\n",
    "                outputs, _ = outputs\n",
    "\n",
    "            optimizer.zero_grad()  # Clear previous gradients\n",
    "            loss = criterion(outputs, traits)  # Calculate loss\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Update model weights\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Append the average loss for this epoch\n",
    "        losses.append(running_loss / len(train_loader))\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
    "    \n",
    "        # clear cache\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "        # Validation Loop\n",
    "        total_batches = len(val_loader) * num_epochs\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():  # Disable gradient calculation for validation\n",
    "            for batch, data in enumerate(val_loader):\n",
    "                progress = 100 * (epoch * len(val_loader) + batch + 1) / total_batches\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}] Progress: [{progress:.2f}%]', end='\\r')\n",
    "                \n",
    "                if has_features:\n",
    "                    images, ids, features, traits = data\n",
    "                    images, ids, features, traits = images.to(device), ids.to(device), features.to(device), traits.to(device)\n",
    "                    outputs = model(images, features)\n",
    "                else:\n",
    "                    images, ids, traits = data\n",
    "                    images, ids, traits = images.to(device), ids.to(device), traits.to(device)\n",
    "                    outputs = model(images)\n",
    "\n",
    "                if isinstance(outputs, tuple):\n",
    "                    outputs, _ = outputs\n",
    "\n",
    "                val_loss += nn.L1Loss()(outputs, traits).item()  # Use MAE (L1 loss) for validation\n",
    "\n",
    "            \n",
    "        val_losses.append(val_loss / len(val_loader))  # Average validation loss for this epoch\n",
    "        print(f'Validation Loss: {val_loss/len(val_loader):.4f}')\n",
    "        # clear cache\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return losses, val_losses\n",
    "\n",
    "\n",
    "# Train the model\n",
    "# training_loss, validation_loss = train_model(base_model, baseline_train_loader, baseline_val_loader, criterion, optimizer, num_epochs=1)\n",
    "training_loss, validation_loss = train_model(plasticity_model, plasticity_train_loader, plasticity_val_loader, criterion, optimizer, num_epochs=1, has_features=True)\n",
    "# training_loss, validation_loss = train_model(world_climate_model, world_climate_train_loader, world_climate_val_loader, criterion, optimizer, num_epochs=1, has_features=True)\n",
    "\n",
    "# Save the trained model\n",
    "# torch.save(base_model.state_dict(), 'inception_v3_baseline.pth')\n",
    "torch.save(plasticity_model.state_dict(), 'inception_v3_plasticity.pth')\n",
    "# torch.save(world_climate_model.state_dict(), 'inception_v3_world_climate.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate IDs: 0\n",
      "Submission file saved\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def test_model(model, test_loader, min_train, max_train, has_features=False):\n",
    "    model = model.to(device)  \n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    predictions = []\n",
    "    seen_ids = set()  # Track seen IDs to avoid duplicates\n",
    "\n",
    "    # Ensure min_train and max_train are on the GPU if necessary\n",
    "    min_train_tensor = torch.tensor(min_train.values).to(device)\n",
    "    max_train_tensor = torch.tensor(max_train.values).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        batchsize = len(test_loader)\n",
    "        duplicate_ids = 0\n",
    "        for batch, data in enumerate(test_loader):\n",
    "            print(f'Progress: [{100*(batch+1)/batchsize:.2f}%]', end='\\r')\n",
    "            if has_features:\n",
    "                images, ids, features = data\n",
    "                images, ids, features = images.to(device), ids.to(device), features.to(device)\n",
    "                outputs = model(images, features)\n",
    "            else:\n",
    "                images, ids = data\n",
    "                images, ids = images.to(device), ids.to(device)\n",
    "                outputs = model(images) \n",
    "            \n",
    "            # Reverse normalization on the GPU\n",
    "            outputs = outputs * (max_train_tensor - min_train_tensor) + min_train_tensor\n",
    "            outputs = torch.pow(10, outputs)\n",
    "\n",
    "            \n",
    "            # Group id with predicted traits (output)\n",
    "            for i, id_val in enumerate(ids):\n",
    "                if id_val.item() not in seen_ids:\n",
    "                    seen_ids.add(id_val.item())\n",
    "                    # Move outputs[i] to CPU before converting to NumPy\n",
    "                    predictions.append([int(id_val.item())] + outputs[i].cpu().numpy().tolist())  \n",
    "                else:\n",
    "                    duplicate_ids += 1\n",
    "        print(f'Number of duplicate IDs: {duplicate_ids}')\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Assuming min_train and max_train were computed earlier during the training data preprocessing\n",
    "# predictions = test_model(base_model, baseline_test_loader, min_train, max_train)\n",
    "predictions = test_model(plasticity_model, plasticity_test_loader, min_train, max_train, has_features=True)\n",
    "# predictions = test_model(world_climate_model, world_climate_test_loader, min_train, max_train, has_features=True)\n",
    "\n",
    "# Convert to numpy array and save to CSV\n",
    "predictions = np.array(predictions, dtype=object)  # Ensure proper handling of mixed types (int and float)\n",
    "np.savetxt('submission.csv', predictions, delimiter=',', fmt='%s', header='id,X4,X11,X18,X26,X50,X3112', comments='')\n",
    "print('Submission file saved')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "wgan.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
